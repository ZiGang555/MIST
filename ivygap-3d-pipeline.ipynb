{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adffb507-2810-4877-8a6c-a80c359aa7ca",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 38.319401,
     "end_time": "2021-06-13T05:21:49.133325",
     "exception": false,
     "start_time": "2021-06-13T05:21:10.813924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, metrics\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import ants\n",
    "\n",
    "#from preprocess import *\n",
    "from model import *\n",
    "from loss import *\n",
    "#from train import *\n",
    "#from inference import *\n",
    "\n",
    "# Set this environment variable to allow ModelCheckpoint to work\n",
    "os.environ['HDF5_USE_FILE_LOCKING'] = 'FALSE'\n",
    "\n",
    "# Set this environment variable to only use the first available GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# For tensorflow 2.x.x allow memory growth on GPU\n",
    "###################################\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "understood-dominant",
   "metadata": {
    "papermill": {
     "duration": 0.075664,
     "end_time": "2021-06-13T05:21:49.539887",
     "exception": false,
     "start_time": "2021-06-13T05:21:49.464223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_paths_csv(base_dir, name_dict, output_csv):\n",
    "    \n",
    "    try:\n",
    "        def get_files(path):\n",
    "            files_list = list()\n",
    "            for root, _, files in os.walk(path, topdown = False):\n",
    "                for name in files:\n",
    "                    files_list.append(os.path.join(root, name))\n",
    "            return files_list\n",
    "\n",
    "        cols = ['id'] + list(names_dict.keys())\n",
    "        df = pd.DataFrame(columns = cols)\n",
    "        row_dict = dict.fromkeys(cols)\n",
    "\n",
    "        ids = os.listdir(base_dir)\n",
    "\n",
    "        for i in ids:\n",
    "            row_dict['id'] = i\n",
    "            path = os.path.join(base_dir, i)\n",
    "            files = get_files(path)\n",
    "\n",
    "            for file in files:\n",
    "                for img_type in name_dict.keys():\n",
    "                    for img_string in name_dict[img_type]:\n",
    "                        if img_string in file:\n",
    "                            row_dict[img_type] = file\n",
    "\n",
    "            df = df.append(row_dict, ignore_index = True)\n",
    "\n",
    "        df.to_csv(output_csv, index = False)\n",
    "    except:\n",
    "        print('ERROR! Returning non-zero exit status.')\n",
    "        return 1\n",
    "    \n",
    "    return 0\n",
    "    \n",
    "    ################# End of function #################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "raising-worship",
   "metadata": {
    "papermill": {
     "duration": 0.303698,
     "end_time": "2021-06-13T05:21:49.891866",
     "exception": false,
     "start_time": "2021-06-13T05:21:49.588168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_dict = {'mask': ['UPenn', 'Segm'],\n",
    "              't1': ['t1_'],\n",
    "              't2': ['t2_'], \n",
    "              'tc': ['t1gd_'], \n",
    "              'fl': ['flair_']}\n",
    "base_dir = '/rsrch1/ip/aecelaya/data/ivygap/IvyGap/'\n",
    "output_csv = 'ivygap_paths.csv'\n",
    "\n",
    "get_paths_csv(base_dir, names_dict, output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ahead-transfer",
   "metadata": {
    "papermill": {
     "duration": 0.027882,
     "end_time": "2021-06-13T05:21:49.934695",
     "exception": false,
     "start_time": "2021-06-13T05:21:49.906813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('ivygap_paths.csv')\n",
    "train, val, _, _ = train_test_split(data, data, test_size = 0.2, random_state = 42)\n",
    "train = train.reset_index(drop = True)\n",
    "val = val.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "technical-philippines",
   "metadata": {
    "papermill": {
     "duration": 0.022221,
     "end_time": "2021-06-13T05:21:49.972146",
     "exception": false,
     "start_time": "2021-06-13T05:21:49.949925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def make_tfrecords(df, filename):\n",
    "#     def _float_feature(value):\n",
    "#         return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "#     # open the file\n",
    "#     writer = tf.io.TFRecordWriter(filename)\n",
    "\n",
    "#     for j in trange(len(df)):\n",
    "#         patient = df.iloc[j].to_dict()\n",
    "#         mask_info = ants.image_header_info(patient['mask'])\n",
    "#         dims = mask_info['dimensions']\n",
    "#         dims = tuple(int(d) for d in dims)\n",
    "#         mask_labels = [0, 1, 2, 4]\n",
    "#         patch_size = 64\n",
    "#         radius = patch_size // 2\n",
    "\n",
    "#         mask = ants.image_read(patient['mask'])\n",
    "#         nz = mask.nonzero()\n",
    "#         mask = mask.numpy()\n",
    "#         mask_numpy = np.empty((*dims, len(mask_labels)))\n",
    "#         for i in range(len(mask_labels)):\n",
    "#             mask_numpy[..., i] = mask == mask_labels[i]\n",
    "\n",
    "#         images = list(patient.values())[2:len(patient)]\n",
    "#         images_numpy = np.empty((*dims, len(images)))\n",
    "#         for i in range(len(images)):\n",
    "#             ants_image = ants.image_read(images[i])\n",
    "#             ants_image = ants_image.numpy()\n",
    "#             ants_image_nz = ants_image[ants_image != 0]\n",
    "#             mean = np.mean(ants_image_nz)\n",
    "#             std = np.std(ants_image_nz)\n",
    "#             ants_image = (ants_image - mean) / std\n",
    "#             ants_image = np.multiply(mask, ants_image)\n",
    "#             images_numpy[..., i] = ants_image\n",
    "\n",
    "#         idx = np.arange(0, len(nz[0]))\n",
    "\n",
    "#         num_points = 20\n",
    "#         cnt = 0\n",
    "#         while cnt < num_points:\n",
    "#             idx_sample = np.random.choice(idx, size = 1)[0]\n",
    "#             point = (nz[0][idx_sample], nz[1][idx_sample], nz[2][idx_sample])\n",
    "#             point_upper = [point[i] + radius in range(0, dims[i] + 1) for i in range(len(point))]\n",
    "#             point_lower = [point[i] - radius in range(0, dims[i] + 1) for i in range(len(point))]\n",
    "#             if False in point_upper or False in point_lower:\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 image_patch = images_numpy[point[0] - radius:point[0] + radius, \n",
    "#                                            point[1] - radius:point[1] + radius, \n",
    "#                                            point[2] - radius:point[2] + radius, \n",
    "#                                            ...]\n",
    "#                 mask_patch = mask_numpy[point[0] - radius:point[0] + radius, \n",
    "#                                         point[1] - radius:point[1] + radius, \n",
    "#                                         point[2] - radius:point[2] + radius, \n",
    "#                                         ...]\n",
    "\n",
    "#                 # Create a feature\n",
    "#                 feature = {'image': _float_feature(image_patch.ravel()),\n",
    "#                             'mask': _float_feature(mask_patch.ravel())}\n",
    "\n",
    "#                 # Create an example protocol buffer\n",
    "#                 example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "#                 # Serialize to string and write on the file\n",
    "#                 writer.write(example.SerializeToString())\n",
    "\n",
    "#                 cnt += 1\n",
    "\n",
    "#     writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "becoming-advice",
   "metadata": {
    "papermill": {
     "duration": 0.023879,
     "end_time": "2021-06-13T05:21:50.011216",
     "exception": false,
     "start_time": "2021-06-13T05:21:49.987337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_points(mask, num_points):\n",
    "    # Return list of randomly sampled non-zero points from image mask\n",
    "    \n",
    "    # Get indicies of non-zero elements of mask\n",
    "    nonzeros = np.nonzero(mask)\n",
    "    \n",
    "    # Randomly sample non-zero indicies\n",
    "    idx = np.arange(0, len(nonzeros[0]))\n",
    "    idx_sample = np.random.choice(idx, size = num_points)\n",
    "    \n",
    "    # Get list of points \n",
    "    points = list()\n",
    "    for i in idx_sample:\n",
    "        points.append((nonzeros[0][i], nonzeros[1][i], nonzeros[2][i]))\n",
    "        \n",
    "    return points\n",
    "\n",
    "def normalize(image, brainmask):\n",
    "    nonzeros = image[image != 0]\n",
    "    mean = np.mean(nonzeros)\n",
    "    std = np.std(nonzeros)\n",
    "    image = (image - mean) / std\n",
    "    image = np.multiply(brainmask, image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grateful-steering",
   "metadata": {
    "papermill": {
     "duration": 0.029514,
     "end_time": "2021-06-13T05:21:50.054663",
     "exception": false,
     "start_time": "2021-06-13T05:21:50.025149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_tfrecords(df, filename):\n",
    "    def _float_feature(value):\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value = value))\n",
    "    \n",
    "    # open the file\n",
    "    writer = tf.io.TFRecordWriter(filename)\n",
    "\n",
    "    for i in trange(len(df)):\n",
    "        patient = df.iloc[i].to_dict()\n",
    "        mask_info = ants.image_header_info(patient['mask'])\n",
    "        dims = mask_info['dimensions']\n",
    "        dims = tuple(int(d) for d in dims)\n",
    "        mask_labels = [0, 1, 2, 4]\n",
    "        patch_size = 64\n",
    "        radius = patch_size // 2\n",
    "\n",
    "        mask_numpy = ants.image_read(patient['mask']).numpy()\n",
    "        mask_numpy = np.pad(mask_numpy, radius)\n",
    "        mask = np.empty((*(dim + patch_size for dim in dims), len(mask_labels)))\n",
    "        for j in range(len(mask_labels)):\n",
    "            mask[..., j] = mask_numpy == mask_labels[j]\n",
    "\n",
    "        image_list = list(patient.values())[2:len(patient)]\n",
    "        image = np.empty((*(dim + patch_size for dim in dims), len(image_list)))\n",
    "        for j in range(len(image_list)):\n",
    "            image_ants = ants.image_read(image_list[j])\n",
    "            brainmask = ants.get_mask(image_ants, cleanup = 0).numpy()\n",
    "            image_numpy = image_ants.numpy()\n",
    "            image_numpy = normalize(image_numpy, brainmask)\n",
    "            \n",
    "            # Pad each image with radius to ensure each point in mask can be picked\n",
    "            image[..., j] = np.pad(image_numpy, radius) \n",
    "            \n",
    "        points = get_points(mask_numpy, 20)\n",
    "        for point in points:\n",
    "            image_patch = image[point[0] - radius:point[0] + radius, \n",
    "                                point[1] - radius:point[1] + radius, \n",
    "                                point[2] - radius:point[2] + radius, \n",
    "                                ...]\n",
    "            mask_patch = mask[point[0] - radius:point[0] + radius, \n",
    "                              point[1] - radius:point[1] + radius, \n",
    "                              point[2] - radius:point[2] + radius, \n",
    "                              ...]\n",
    "            \n",
    "            # Create a feature\n",
    "            feature = {'image': _float_feature(image_patch.ravel()),\n",
    "                        'mask': _float_feature(mask_patch.ravel())}\n",
    "\n",
    "            # Create an example protocol buffer\n",
    "            example = tf.train.Example(features = tf.train.Features(feature = feature))\n",
    "\n",
    "            # Serialize to string and write on the file\n",
    "            writer.write(example.SerializeToString())\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "constitutional-progressive",
   "metadata": {
    "papermill": {
     "duration": 573.438531,
     "end_time": "2021-06-13T05:31:23.507473",
     "exception": false,
     "start_time": "2021-06-13T05:21:50.068942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [04:30<00:00, 10.00s/it]\n",
      "100%|██████████| 7/7 [01:03<00:00,  9.06s/it]\n"
     ]
    }
   ],
   "source": [
    "make_tfrecords(train, 'train.tfrecords')\n",
    "make_tfrecords(val, 'val.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adapted-blade",
   "metadata": {
    "papermill": {
     "duration": 0.03209,
     "end_time": "2021-06-13T05:31:23.563316",
     "exception": false,
     "start_time": "2021-06-13T05:31:23.531226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode(serialized_example):\n",
    "    # Decode examples stored in TFRecord\n",
    "    # NOTE: make sure to specify the correct dimensions for the images\n",
    "    features = tf.io.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={'image': tf.io.FixedLenFeature([64, 64, 64, 4], tf.float32),\n",
    "                  'mask': tf.io.FixedLenFeature([64, 64, 64, 4], tf.float32)})\n",
    "\n",
    "    # NOTE: No need to cast these features, as they are already `tf.float32` values.\n",
    "    return features['image'], features['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "documented-westminster",
   "metadata": {
    "papermill": {
     "duration": 0.035829,
     "end_time": "2021-06-13T05:31:23.623581",
     "exception": false,
     "start_time": "2021-06-13T05:31:23.587752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_model(batch_size, pocket):\n",
    "    \n",
    "    def get_dataset(tfrecords_file, batch_size):\n",
    "        ds = tf.data.TFRecordDataset(tfrecords_file).map(decode, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "        ds = ds.shuffle(buffer_size = 25)\n",
    "        ds = ds.batch(batch_size = batch_size, drop_remainder = True)\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "        return ds\n",
    "    \n",
    "    train = get_dataset('train.tfrecords', batch_size)    \n",
    "    val = get_dataset('val.tfrecords', batch_size)\n",
    "    \n",
    "    # Create logs directory based on architecture and batch size\n",
    "    if pocket:\n",
    "        print('Running pocket u-net with batch size ' + str(int(batch_size)))\n",
    "        #logs = 'logs/' + 'pocket_unet_batchsize_' + str(batchSize)\n",
    "    else:\n",
    "        print('Running full u-net with batch size ' + str(int(batch_size)))\n",
    "        #logs = 'logs/' + 'full_unet_batchsize_' + str(batchSize)\n",
    "\n",
    "    # Create model\n",
    "#     model = PocketNet(inputShape = (64, 64, 64, 4), \n",
    "#                       numClasses = 4, \n",
    "#                       mode = 'seg', \n",
    "#                       net = 'densenet', \n",
    "#                       pocket = pocket, \n",
    "#                       initFilters = 16, \n",
    "#                       depth = 4)\n",
    "\n",
    "    model = DenseNet((64, 64, 64, 4), 16, 4, 4, True).get_model()\n",
    "    \n",
    "    # Compile model with Dice loss\n",
    "    model.compile(optimizer = 'adam', loss = [dice_loss_l2_weighted], metrics = [dice_loss_l2])\n",
    "    \n",
    "    # Reduce learning rate by 0.5 if validation dice coefficient does not improve after 5 epochs\n",
    "    reduceLr = ReduceLROnPlateau(monitor = 'val_loss', \n",
    "                                 mode = 'min',\n",
    "                                 factor = 0.5, \n",
    "                                 patience = 5, \n",
    "                                 min_lr = 0.000001, \n",
    "                                 verbose = 1)\n",
    "\n",
    "    if pocket:\n",
    "        modelName = 'pocket.h5'\n",
    "    else:\n",
    "        modelName = 'full.h5'\n",
    "\n",
    "    saveBestModel = ModelCheckpoint(filepath = modelName, \n",
    "                                    monitor = 'val_loss', \n",
    "                                    verbose = 1, \n",
    "                                    save_best_only = True)\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(train, \n",
    "              epochs = 35, \n",
    "              steps_per_epoch = 135, \n",
    "              validation_data = val, \n",
    "              validation_steps = 35, \n",
    "              callbacks = [reduceLr, saveBestModel], \n",
    "              verbose = 1) \n",
    "    \n",
    "    ##### END OF FUNCTION #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "passing-bristol",
   "metadata": {
    "papermill": {
     "duration": 5986.679105,
     "end_time": "2021-06-13T07:11:10.326435",
     "exception": false,
     "start_time": "2021-06-13T05:31:23.647330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running pocket u-net with batch size 4\n",
      "Epoch 1/35\n",
      "135/135 [==============================] - 43s 214ms/step - loss: 0.4861 - dice_loss_l2: 0.4930 - val_loss: 0.2626 - val_dice_loss_l2: 0.3523\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.26263, saving model to pocket.h5\n",
      "Epoch 2/35\n",
      "135/135 [==============================] - 29s 216ms/step - loss: 0.3297 - dice_loss_l2: 0.4040 - val_loss: 0.2980 - val_dice_loss_l2: 0.2175\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.26263\n",
      "Epoch 3/35\n",
      "135/135 [==============================] - 30s 219ms/step - loss: 0.2683 - dice_loss_l2: 0.2862 - val_loss: 0.2751 - val_dice_loss_l2: 0.2198\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.26263\n",
      "Epoch 4/35\n",
      "135/135 [==============================] - 30s 220ms/step - loss: 0.2421 - dice_loss_l2: 0.2380 - val_loss: 0.1707 - val_dice_loss_l2: 0.1418\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.26263 to 0.17074, saving model to pocket.h5\n",
      "Epoch 5/35\n",
      "135/135 [==============================] - 30s 220ms/step - loss: 0.1828 - dice_loss_l2: 0.1807 - val_loss: 0.1765 - val_dice_loss_l2: 0.1452\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.17074\n",
      "Epoch 6/35\n",
      "135/135 [==============================] - 30s 220ms/step - loss: 0.1743 - dice_loss_l2: 0.1782 - val_loss: 0.1823 - val_dice_loss_l2: 0.1394\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.17074\n",
      "Epoch 7/35\n",
      "135/135 [==============================] - 30s 220ms/step - loss: 0.1323 - dice_loss_l2: 0.1423 - val_loss: 0.1562 - val_dice_loss_l2: 0.1246\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.17074 to 0.15623, saving model to pocket.h5\n",
      "Epoch 8/35\n",
      "135/135 [==============================] - 30s 221ms/step - loss: 0.1080 - dice_loss_l2: 0.1229 - val_loss: 0.1674 - val_dice_loss_l2: 0.1245\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.15623\n",
      "Epoch 9/35\n",
      "135/135 [==============================] - 30s 220ms/step - loss: 0.0984 - dice_loss_l2: 0.1123 - val_loss: 0.1611 - val_dice_loss_l2: 0.1190\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.15623\n",
      "Epoch 10/35\n",
      "135/135 [==============================] - 30s 221ms/step - loss: 0.0930 - dice_loss_l2: 0.1054 - val_loss: 0.1535 - val_dice_loss_l2: 0.1135\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.15623 to 0.15350, saving model to pocket.h5\n",
      "Epoch 11/35\n",
      "135/135 [==============================] - 30s 221ms/step - loss: 0.0871 - dice_loss_l2: 0.0981 - val_loss: 0.1515 - val_dice_loss_l2: 0.1117\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.15350 to 0.15153, saving model to pocket.h5\n",
      "Epoch 12/35\n",
      "135/135 [==============================] - 30s 222ms/step - loss: 0.0804 - dice_loss_l2: 0.0912 - val_loss: 0.1441 - val_dice_loss_l2: 0.1062\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.15153 to 0.14414, saving model to pocket.h5\n",
      "Epoch 13/35\n",
      "135/135 [==============================] - 30s 221ms/step - loss: 0.0771 - dice_loss_l2: 0.0879 - val_loss: 0.1241 - val_dice_loss_l2: 0.1001\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.14414 to 0.12410, saving model to pocket.h5\n",
      "Epoch 14/35\n",
      "135/135 [==============================] - 30s 221ms/step - loss: 0.0764 - dice_loss_l2: 0.0864 - val_loss: 0.1396 - val_dice_loss_l2: 0.1057\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.12410\n",
      "Epoch 15/35\n",
      "135/135 [==============================] - 30s 221ms/step - loss: 0.0868 - dice_loss_l2: 0.0990 - val_loss: 0.1503 - val_dice_loss_l2: 0.1103\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.12410\n",
      "Epoch 16/35\n",
      "135/135 [==============================] - 30s 221ms/step - loss: 0.0739 - dice_loss_l2: 0.0835 - val_loss: 0.1419 - val_dice_loss_l2: 0.1025\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.12410\n",
      "Epoch 17/35\n",
      "135/135 [==============================] - 30s 221ms/step - loss: 0.0670 - dice_loss_l2: 0.0759 - val_loss: 0.1482 - val_dice_loss_l2: 0.1052\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.12410\n",
      "Epoch 18/35\n",
      "135/135 [==============================] - 30s 222ms/step - loss: 0.0772 - dice_loss_l2: 0.0857 - val_loss: 0.1209 - val_dice_loss_l2: 0.0967\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.12410 to 0.12092, saving model to pocket.h5\n",
      "Epoch 19/35\n",
      "135/135 [==============================] - 30s 222ms/step - loss: 0.0733 - dice_loss_l2: 0.0818 - val_loss: 0.1249 - val_dice_loss_l2: 0.0999\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.12092\n",
      "Epoch 20/35\n",
      "135/135 [==============================] - 30s 221ms/step - loss: 0.0623 - dice_loss_l2: 0.0703 - val_loss: 0.1246 - val_dice_loss_l2: 0.0955\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.12092\n",
      "Epoch 21/35\n",
      "135/135 [==============================] - 30s 222ms/step - loss: 0.0589 - dice_loss_l2: 0.0664 - val_loss: 0.1396 - val_dice_loss_l2: 0.1019\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.12092\n",
      "Epoch 22/35\n",
      "135/135 [==============================] - 30s 222ms/step - loss: 0.0567 - dice_loss_l2: 0.0639 - val_loss: 0.1325 - val_dice_loss_l2: 0.0987\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.12092\n",
      "Epoch 23/35\n",
      "135/135 [==============================] - 30s 221ms/step - loss: 0.0538 - dice_loss_l2: 0.0608 - val_loss: 0.1351 - val_dice_loss_l2: 0.0992\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.12092\n",
      "Epoch 24/35\n",
      "135/135 [==============================] - 30s 221ms/step - loss: 0.0519 - dice_loss_l2: 0.0584 - val_loss: 0.1267 - val_dice_loss_l2: 0.0965\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.12092\n",
      "Epoch 25/35\n",
      "135/135 [==============================] - 30s 222ms/step - loss: 0.0503 - dice_loss_l2: 0.0563 - val_loss: 0.1254 - val_dice_loss_l2: 0.0970\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.12092\n",
      "Epoch 26/35\n",
      "135/135 [==============================] - 30s 221ms/step - loss: 0.0498 - dice_loss_l2: 0.0548 - val_loss: 0.1066 - val_dice_loss_l2: 0.0913\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.12092 to 0.10658, saving model to pocket.h5\n",
      "Epoch 27/35\n",
      "135/135 [==============================] - 30s 221ms/step - loss: 0.0483 - dice_loss_l2: 0.0539 - val_loss: 0.1250 - val_dice_loss_l2: 0.0967\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.10658\n",
      "Epoch 28/35\n",
      "135/135 [==============================] - 30s 222ms/step - loss: 0.0476 - dice_loss_l2: 0.0524 - val_loss: 0.1298 - val_dice_loss_l2: 0.0981\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.10658\n",
      "Epoch 29/35\n",
      "135/135 [==============================] - 30s 221ms/step - loss: 0.0457 - dice_loss_l2: 0.0509 - val_loss: 0.1226 - val_dice_loss_l2: 0.0960\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.10658\n",
      "Epoch 30/35\n",
      "135/135 [==============================] - 30s 222ms/step - loss: 0.0448 - dice_loss_l2: 0.0498 - val_loss: 0.1241 - val_dice_loss_l2: 0.0961\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.10658\n",
      "Epoch 31/35\n",
      "135/135 [==============================] - 30s 222ms/step - loss: 0.0434 - dice_loss_l2: 0.0484 - val_loss: 0.1283 - val_dice_loss_l2: 0.0978\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.10658\n",
      "Epoch 32/35\n",
      "135/135 [==============================] - 30s 221ms/step - loss: 0.0432 - dice_loss_l2: 0.0484 - val_loss: 0.1188 - val_dice_loss_l2: 0.0930\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.10658\n",
      "Epoch 33/35\n",
      "135/135 [==============================] - 30s 221ms/step - loss: 0.0422 - dice_loss_l2: 0.0471 - val_loss: 0.1186 - val_dice_loss_l2: 0.0939\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.10658\n",
      "Epoch 34/35\n",
      "135/135 [==============================] - 30s 223ms/step - loss: 0.0418 - dice_loss_l2: 0.0466 - val_loss: 0.1226 - val_dice_loss_l2: 0.0956\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.10658\n",
      "Epoch 35/35\n",
      "135/135 [==============================] - 30s 223ms/step - loss: 0.0406 - dice_loss_l2: 0.0450 - val_loss: 0.1230 - val_dice_loss_l2: 0.0956\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.10658\n"
     ]
    }
   ],
   "source": [
    "run_model(batch_size = 4, pocket = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "figured-steel",
   "metadata": {
    "papermill": {
     "duration": 4.341075,
     "end_time": "2021-06-13T07:11:18.163917",
     "exception": false,
     "start_time": "2021-06-13T07:11:13.822842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = load_model('pocket.h5', custom_objects = {'dice_loss_l2': dice_loss_l2, 'dice_loss_l2_weighted': dice_loss_l2_weighted})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hairy-serum",
   "metadata": {
    "papermill": {
     "duration": 3.746799,
     "end_time": "2021-06-13T07:11:25.911140",
     "exception": false,
     "start_time": "2021-06-13T07:11:22.164341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_strides(dims, patch_size):\n",
    "    def get_factors(n):    \n",
    "            return [i for i in range(1, n + 1) if n % i == 0]\n",
    "\n",
    "    strides = list()\n",
    "    for dim in dims:\n",
    "        factors = get_factors(dim - patch_size)\n",
    "        factors.sort()\n",
    "        strides.append(np.max([factor for factor in factors if factor < patch_size]))\n",
    "\n",
    "    return strides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caring-brown",
   "metadata": {
    "papermill": {
     "duration": 3.577254,
     "end_time": "2021-06-13T07:11:32.963031",
     "exception": false,
     "start_time": "2021-06-13T07:11:29.385777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model, df):\n",
    "    for i in trange(len(df)):\n",
    "        patient = df.iloc[i].to_dict()\n",
    "        mask_info = ants.image_header_info(patient['mask'])\n",
    "        dims = mask_info['dimensions']\n",
    "        dims = tuple(int(d) for d in dims)\n",
    "        mask_labels = [0, 1, 2, 4]\n",
    "        patch_size = 64\n",
    "        radius = patch_size // 2\n",
    "\n",
    "        image_list = list(patient.values())[2:len(patient)]\n",
    "        image = np.empty((*(dim for dim in dims), len(image_list)))\n",
    "        for j in range(len(image_list)):\n",
    "            image_ants = ants.image_read(image_list[j])\n",
    "            brainmask = ants.get_mask(image_ants, cleanup = 0).numpy()\n",
    "            image_numpy = image_ants.numpy()\n",
    "            image_numpy = normalize(image_numpy, brainmask)\n",
    "            image[..., j] = image_numpy\n",
    "            \n",
    "        strides = get_strides(dims, patch_size)\n",
    "        pred = np.empty((*dims, len(mask_labels)))\n",
    "        for i in range(0, dims[0] - patch_size + 1, strides[0]):\n",
    "            for j in range(0, dims[1] - patch_size + 1, strides[1]):\n",
    "                for k in range(0, dims[2] - patch_size + 1, strides[2]):\n",
    "                    patch = image[i:(i + patch_size), j:(j + patch_size), k:(k + patch_size), ...]\n",
    "                    patch = patch.reshape((1, patch_size, patch_size, patch_size, len(mask_labels)))\n",
    "                    pred_patch = model.predict(patch)\n",
    "                    pred[i:(i + patch_size), j:(j + patch_size), k:(k + patch_size), ...] = pred_patch\n",
    "                    \n",
    "        pred = pred.argmax(axis = -1)\n",
    "        pred[pred == 3] = 4\n",
    "        \n",
    "        original = ants.image_read(patient['mask'])\n",
    "        pred = original.new_image_like(data = pred.astype(np.float32))\n",
    "        pred_name = patient['id'] + '_pred_W.nii.gz'\n",
    "        ants.image_write(pred, pred_name)\n",
    "                    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "joint-kinase",
   "metadata": {
    "papermill": {
     "duration": 135.871646,
     "end_time": "2021-06-13T07:13:52.665333",
     "exception": false,
     "start_time": "2021-06-13T07:11:36.793687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [01:34<00:00, 13.56s/it]\n"
     ]
    }
   ],
   "source": [
    "pred = inference(model, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "congressional-rainbow",
   "metadata": {
    "papermill": {
     "duration": 3.779082,
     "end_time": "2021-06-13T07:13:59.941971",
     "exception": false,
     "start_time": "2021-06-13T07:13:56.162889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mask</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>tc</th>\n",
       "      <th>fl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W8</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W8/W8_1...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W8/W8_1...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W8/W8_1...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W8/W8_1...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W8/W8_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W6</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W6/W6_1...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W6/W6_1...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W6/W6_1...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W6/W6_1...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W6/W6_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W2</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W2/W2_1...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W2/W2_1...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W2/W2_1...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W2/W2_1...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W2/W2_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W18</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W18/W18...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W18/W18...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W18/W18...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W18/W18...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W18/W18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W7</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W7/W7_1...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W7/W7_1...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W7/W7_1...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W7/W7_1...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W7/W7_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>W55</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W55/W55...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W55/W55...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W55/W55...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W55/W55...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W55/W55...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>W30</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W30/W30...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W30/W30...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W30/W30...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W30/W30...</td>\n",
       "      <td>/rsrch1/ip/aecelaya/data/ivygap/IvyGap/W30/W30...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                               mask  \\\n",
       "0   W8  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W8/W8_1...   \n",
       "1   W6  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W6/W6_1...   \n",
       "2   W2  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W2/W2_1...   \n",
       "3  W18  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W18/W18...   \n",
       "4   W7  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W7/W7_1...   \n",
       "5  W55  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W55/W55...   \n",
       "6  W30  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W30/W30...   \n",
       "\n",
       "                                                  t1  \\\n",
       "0  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W8/W8_1...   \n",
       "1  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W6/W6_1...   \n",
       "2  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W2/W2_1...   \n",
       "3  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W18/W18...   \n",
       "4  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W7/W7_1...   \n",
       "5  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W55/W55...   \n",
       "6  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W30/W30...   \n",
       "\n",
       "                                                  t2  \\\n",
       "0  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W8/W8_1...   \n",
       "1  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W6/W6_1...   \n",
       "2  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W2/W2_1...   \n",
       "3  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W18/W18...   \n",
       "4  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W7/W7_1...   \n",
       "5  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W55/W55...   \n",
       "6  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W30/W30...   \n",
       "\n",
       "                                                  tc  \\\n",
       "0  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W8/W8_1...   \n",
       "1  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W6/W6_1...   \n",
       "2  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W2/W2_1...   \n",
       "3  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W18/W18...   \n",
       "4  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W7/W7_1...   \n",
       "5  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W55/W55...   \n",
       "6  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W30/W30...   \n",
       "\n",
       "                                                  fl  \n",
       "0  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W8/W8_1...  \n",
       "1  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W6/W6_1...  \n",
       "2  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W2/W2_1...  \n",
       "3  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W18/W18...  \n",
       "4  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W7/W7_1...  \n",
       "5  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W55/W55...  \n",
       "6  /rsrch1/ip/aecelaya/data/ivygap/IvyGap/W30/W30...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eba44e-930b-43ca-8848-d33261c91e52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6782.237025,
   "end_time": "2021-06-13T07:14:06.608107",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-13T05:21:04.371082",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

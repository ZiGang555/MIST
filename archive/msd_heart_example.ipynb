{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1bdad30-a998-4774-82ea-12c03fda144f",
   "metadata": {},
   "source": [
    "# MIST Example Notebook - MSD Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aac4c82-1f52-4835-b613-43abad6fd742",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "This example is intended to be run out of a Docker container with TensorFlow 2.6.0 or later. Once you start this Jupyter notebook in a container, uncomment the cell below to install some necessary dependencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d68e72-2ccf-4611-b951-c0ba38fa031a",
   "metadata": {},
   "source": [
    "## Import the necessary scripts\n",
    "\n",
    "Import the necessary scirpts from the `mist/` directory. The three main components are the Preprocess, RunTime, and Inference classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c769b783-bb87-49f4-95f4-ff4b12add8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 18:28:22.083084: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Import preprocess, runtime, and inference scripts\n",
    "from mist.preprocess import Preprocess\n",
    "from mist.runtime import RunTime\n",
    "\n",
    "# Import the msd conversion tool from mist.utils\n",
    "from mist.utils import convert_msd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c79f648-73d9-4ab6-85d8-d6bb42dd7511",
   "metadata": {},
   "source": [
    "## Convert MSD data to MIST format\n",
    "\n",
    "MIST provides a simple conversion script to convert MSD formated data to MIST compatible datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b8f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "msd_source = '/tf/data/msd/original/Task02_Heart/'\n",
    "mist_dest = '/tf/data/msd/mist/Task02_Heart/'\n",
    "convert_msd(msd_source, mist_dest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e43fe4",
   "metadata": {},
   "source": [
    "MIST will convert the MSD dataset and provide a sample user parameters JSON file. The parameters JSON file will be written to the same destination as the newly formated MIST data. You can run the MIST pipeline with this provided parameters file as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a974172",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = '/tf/data/msd/mist/Task02_Heart/user_params.json'\n",
    "\n",
    "# Preprocess training data\n",
    "preproccess = Preprocess(json_file)\n",
    "preproccess.run()\n",
    "\n",
    "# # Run MIST pipeline\n",
    "runtime = RunTime(json_file)\n",
    "runtime.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d29160",
   "metadata": {},
   "source": [
    "Alternatively, you can copy and paste the printed output of the msd conversion script and customize the inputs to the MSD pipeline. Below we use mutli-gpu training, specify which folds to train on, modify the number of epochs per fold, and give the pipeline a specific patch size to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e409f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up GPU(s)...\n",
      "Starting fold 0...\n",
      "Fold 0: Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 18:28:26.902980: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-24 18:28:27.517570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46286 MB memory:  -> device: 0, name: Quadro RTX 8000, pci bus id: 0000:da:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Input to reshape is a tensor with 14080000 values, but the requested shape has 28160000\n\t [[{{node Reshape_1}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) INVALID_ARGUMENT:  Input to reshape is a tensor with 14080000 values, but the requested shape has 28160000\n\t [[{{node Reshape_1}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_10248]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Preprocess training data\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# preprocess = Preprocess(json_file)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# preprocess.run()\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Run MIST pipeline\u001b[39;00m\n\u001b[1;32m     32\u001b[0m runtime \u001b[38;5;241m=\u001b[39m RunTime(json_file)\n\u001b[0;32m---> 33\u001b[0m \u001b[43mruntime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/rsrch1/ip/aecelaya/github/MIST/mist/runtime.py:911\u001b[0m, in \u001b[0;36mRunTime.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns \u001b[38;5;241m=\u001b[39m results_cols)\n\u001b[1;32m    909\u001b[0m \u001b[38;5;66;03m# Run training pipeline\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;66;03m# self.loss = Loss(self.json_file)\u001b[39;00m\n\u001b[0;32m--> 911\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;66;03m# Get final statistics\u001b[39;00m\n\u001b[1;32m    914\u001b[0m mean_row \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "File \u001b[0;32m/rsrch1/ip/aecelaya/github/MIST/mist/runtime.py:736\u001b[0m, in \u001b[0;36mRunTime.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    733\u001b[0m         model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m opt, loss \u001b[38;5;241m=\u001b[39m [loss_fn])\n\u001b[1;32m    735\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m          \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m K\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[1;32m    740\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Input to reshape is a tensor with 14080000 values, but the requested shape has 28160000\n\t [[{{node Reshape_1}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) INVALID_ARGUMENT:  Input to reshape is a tensor with 14080000 values, but the requested shape has 28160000\n\t [[{{node Reshape_1}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_10248]"
     ]
    }
   ],
   "source": [
    "user_params = {'train_data_dir': '/rsrch1/ip/aecelaya/data/msd/mist/Task02_Heart/raw/train',\n",
    "               'test_data_dir': '/rsrch1/ip/aecelaya/data/msd/mist/Task02_Heart/raw/test',\n",
    "               'processed_data_dir': '/rsrch1/ip/aecelaya/data/msd/mist/Task02_Heart/tfrecord',\n",
    "               'log_dir': '/rsrch1/ip/aecelaya/data/msd/mist/Task02_Heart/logs',\n",
    "               'base_model_name': 'LeftAtrium',\n",
    "               'model_dir': '/rsrch1/ip/aecelaya/data/msd/mist/Task02_Heart/models',\n",
    "               'prediction_dir': '/rsrch1/ip/aecelaya/data/msd/mist/Task02_Heart/predictions',\n",
    "               'raw_paths_csv': '/rsrch1/ip/aecelaya/data/msd/mist/Task02_Heart/paths.csv',\n",
    "               'inferred_params': '/rsrch1/ip/aecelaya/data/msd/mist/Task02_Heart/inferred_params.json',\n",
    "               'results_csv': '/rsrch1/ip/aecelaya/data/msd/mist/Task02_Heart/results.csv',\n",
    "               'modality': 'mr',\n",
    "               'mask': ['mask.nii.gz'],\n",
    "               'images': {'MRI': ['MRI.nii.gz']},\n",
    "               'labels': [0, 1],\n",
    "               'final_classes': {'left_atrium': [1]},\n",
    "               'loss': 'dice_ce',\n",
    "               'model': 'unet',\n",
    "               'folds': 0,\n",
    "               'gpu': 6,\n",
    "               'epochs': 50, \n",
    "               'patch_size': [128, 128, 128]}\n",
    "\n",
    "json_file = '/rsrch1/ip/aecelaya/data/msd/mist/Task02_Heart/user_params.json'\n",
    "with open(json_file, 'w') as outfile: \n",
    "    json.dump(user_params, outfile, indent = 2)\n",
    "    \n",
    "# Preprocess training data\n",
    "# preprocess = Preprocess(json_file)\n",
    "# preprocess.run()\n",
    "\n",
    "# Run MIST pipeline\n",
    "runtime = RunTime(json_file)\n",
    "runtime.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012e0d56-dca3-4b28-ab56-1238547a9e11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
